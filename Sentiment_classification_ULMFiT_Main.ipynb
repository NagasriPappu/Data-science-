{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sentiment_classification_ULMFiT_Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouBT2pwGU3u1",
        "outputId": "37c750a8-b5fc-4fba-c84a-f03d48732e59"
      },
      "source": [
        "#hide\n",
        "!pip install torch\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/koushik/opt/anaconda3/lib/python3.7/site-packages (1.7.0)\r\n",
            "Requirement already satisfied: typing-extensions in /Users/koushik/opt/anaconda3/lib/python3.7/site-packages (from torch) (3.7.4.2)\r\n",
            "Requirement already satisfied: dataclasses in /Users/koushik/opt/anaconda3/lib/python3.7/site-packages (from torch) (0.6)\r\n",
            "Requirement already satisfied: future in /Users/koushik/opt/anaconda3/lib/python3.7/site-packages (from torch) (0.18.2)\r\n",
            "Requirement already satisfied: numpy in /Users/koushik/opt/anaconda3/lib/python3.7/site-packages (from torch) (1.19.5)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDDsKBMKU3u2"
      },
      "source": [
        "#hide\n",
        "from fastbook import *\n",
        "from fastai.text.all import *\n",
        "from IPython.display import display,HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbEdd9xhnjRQ",
        "outputId": "95093fef-3961-4a88-dfd5-30f195a71255"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9JjSbQKU3u2"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxOLsBW2UZOH"
      },
      "source": [
        "txt = \"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9Psv_tRUeGY",
        "outputId": "ca96a4ff-dad3-4506-8ae8-86ffca03bb64"
      },
      "source": [
        "spacy = WordTokenizer()\n",
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks, 30))\n",
        "\n",
        "## \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#154) ['Basically','there',\"'s\",'a','family','where','a','little','boy','(','Jake',')','thinks','there',\"'s\",'a','zombie','in','his','closet','&','his','parents','are','fighting','all','the','time.<br','/><br','/>This'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSArzKenVMeM",
        "outputId": "ab12b464-d74d-47d5-8ed6-f91436d97b07"
      },
      "source": [
        "first(spacy(['The U.S. dollar $1 is $1.00.']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9) ['The','U.S.','dollar','$','1','is','$','1.00','.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuPNhgK3Vhb7"
      },
      "source": [
        "fastai then adds some additional functionality to the tokenization process with the `Tokenizer` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkc696cZVZt1",
        "outputId": "a55798f0-ccce-428f-fa8c-937048151c00"
      },
      "source": [
        "tkn = Tokenizer(spacy)\n",
        "print(coll_repr(tkn(txt), 50))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#171) ['xxbos','xxmaj','basically','there',\"'s\",'a','family','where','a','little','boy','(','jake',')','thinks','there',\"'s\",'a','zombie','in','his','closet','&','his','parents','are','fighting','all','the','time','.','\\n\\n','xxmaj','this','movie','is','slower','than','a','soap','opera','â€¦','and','suddenly',',','xxmaj','jake','decides','to','become'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-_PPggd-2RS",
        "outputId": "661b4b8e-3309-49c2-93ec-b3964baf8367"
      },
      "source": [
        "print(coll_repr(tkn('i like the movie soooooo much\\n. I dont like'))) #I like USA usa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#16) ['xxbos','i','like','the','movie','s','xxrep','6','o','much'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odjTTZ6mtkv4"
      },
      "source": [
        "The rules are all listed below, here is the meaning of the special tokens:\n",
        "\n",
        "- `UNK (xxunk)` is for an unknown word (one that isn't present in the current vocabulary)\n",
        "- `PAD (xxpad)` is the token used for padding, if we need to regroup several texts of different lengths in a batch\n",
        "- `BOS (xxbos)` represents the beginning of a text in your record\n",
        "- `FLD (xxfld)` is used if you set mark_fields=True in your TokenizeProcessor to separate the different fields of texts (if your texts are loaded from several columns in a dataframe)\n",
        "- `TK_MAJ (xxmaj)` is used to indicate the next word begins with a capital in the original text\n",
        "- `TK_UP (xxup)` is used to indicate the next word is written in all caps in the original text\n",
        "- `TK_REP (xxrep)` is used to indicate the next character is repeated n times in the original text (usage xxrep n {char})\n",
        "- `TK_WREP(xxwrep)` is used to indicate the next word is repeated n times in the original text (usage xxwrep n {word})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrPylByYU3u3"
      },
      "source": [
        "Here is a brief summary of what each does:\n",
        "\n",
        "- `fix_html`:: Replaces special HTML characters with a readable version (IMDb reviews have quite a few of these)\n",
        "- `replace_rep`:: Replaces any character repeated three times or more with a special token for repetition (`xxrep`), the number of times it's repeated, then the character\n",
        "- `replace_wrep`:: Replaces any word repeated three times or more with a special token for word repetition (`xxwrep`), the number of times it's repeated, then the word\n",
        "- `spec_add_spaces`:: Adds spaces around / and #\n",
        "- `rm_useless_spaces`:: Removes all repetitions of the space character\n",
        "- `replace_all_caps`:: Lowercases a word written in all caps and adds a special token for all caps (`xxcap`) in front of it\n",
        "- `replace_maj`:: Lowercases a capitalized word and adds a special token for capitalized (`xxmaj`) in front of it\n",
        "- `lowercase`:: Lowercases all text and adds a special token at the beginning (`xxbos`) and/or the end (`xxeos`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAtQENlH8MVr"
      },
      "source": [
        "### Reading IMDB data and Preparing Dataframe for DataLoader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ari5iUUGrhW-",
        "outputId": "dcec3a1c-45a3-4297-92bb-4fd97dc7551b"
      },
      "source": [
        "path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/Users/koushik/Downloads/20210320_Batch86_87_DSC7240o_Lab_Sentiment_classification_ULMFiT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6gESOebU3u2",
        "outputId": "6efc4f87-fb73-4aa7-9d16-e5d8c6bf79b8"
      },
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv', header=0)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "YIvZ6XaSU3u2",
        "outputId": "0aac50d0-af53-4aa0-ba42-c5add1baa3df"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses main...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with so...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of conta...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review  \\\n",
              "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses main...   \n",
              "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his ...   \n",
              "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've ...   \n",
              "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with so...   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of conta...   \n",
              "\n",
              "  sentiment  \n",
              "0  positive  \n",
              "1  positive  \n",
              "2  positive  \n",
              "3  negative  \n",
              "4  positive  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jhjxHKe8VDa"
      },
      "source": [
        "data.columns = ['text', 'label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "unUn9w3S8VAR",
        "outputId": "c9199b64-8e61-4d98-e96d-064cfb7068e4"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses main...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with so...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of conta...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
              "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses main...   \n",
              "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his ...   \n",
              "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've ...   \n",
              "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with so...   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of conta...   \n",
              "\n",
              "      label  \n",
              "0  positive  \n",
              "1  positive  \n",
              "2  positive  \n",
              "3  negative  \n",
              "4  positive  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBE1herkU3u7"
      },
      "source": [
        "### Language Model Using DataBlock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqn8Wxe1U3u7"
      },
      "source": [
        "fastai handles tokenization and numericalization automatically when `TextBlock` is passed to `DataBlock`. All of the arguments that can be passed to `Tokenize` and `Numericalize` can also be passed to `TextBlock`.\n",
        "\n",
        "Here's how we use `TextBlock` to create a language model, using fastai's defaults:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "We6MpTY7U3u7",
        "outputId": "48ed87c2-d5d0-4106-c7fd-f45bc2447b21"
      },
      "source": [
        "dls_lm = DataBlock(\n",
        "    blocks=TextBlock.from_df('text', is_lm=True),\n",
        "    get_x=ColReader('text'), \n",
        "    splitter=RandomSplitter(0.1)\n",
        ").dataloaders(data, bs=128, seq_len=80)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/koushik/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "uM2zCSSZU3u7",
        "outputId": "d51d683b-700a-45e0-9259-f3af0276041b"
      },
      "source": [
        "dls_lm.show_batch(max_n=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj if this awful film moved at a snails pace it would at least be xxunk grass grow would be more interesting . xxmaj it was painful to sit through and i only stayed in the theatre to see how all the cruel teens would xxunk is xxmaj brian depalma xxrep 4 ? xxbos xxmaj after reading the first 5 reviews on imdb i was very enthusiastic about this movie . xxmaj but it 's really an awful movie</td>\n",
              "      <td>xxmaj if this awful film moved at a snails pace it would at least be xxunk grass grow would be more interesting . xxmaj it was painful to sit through and i only stayed in the theatre to see how all the cruel teens would xxunk is xxmaj brian depalma xxrep 4 ? xxbos xxmaj after reading the first 5 reviews on imdb i was very enthusiastic about this movie . xxmaj but it 's really an awful movie ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>most patronizing \" world music \" imaginable . xxmaj this is a tourist film , and a lousy one . xxmaj what really kills it is the incoherent sequences . xxmaj india , xxmaj egypt , xxmaj south xxmaj america , xxmaj africa , etc , etc . xxmaj no transitions , no visual explanation of why we 're suddenly ten thousand miles away , no ideas expressed in images . xxmaj just a bunch of footage of third -</td>\n",
              "      <td>patronizing \" world music \" imaginable . xxmaj this is a tourist film , and a lousy one . xxmaj what really kills it is the incoherent sequences . xxmaj india , xxmaj egypt , xxmaj south xxmaj america , xxmaj africa , etc , etc . xxmaj no transitions , no visual explanation of why we 're suddenly ten thousand miles away , no ideas expressed in images . xxmaj just a bunch of footage of third - xxunk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLGijaZMU3u8"
      },
      "source": [
        "Now that our data is ready, we can fine-tune the pretrained language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDVLS0ugU3u8"
      },
      "source": [
        "### Fine-Tuning the Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20EBPjHeU3u8"
      },
      "source": [
        "To convert the integer word indices into activations that we can use for our neural network, we will use embeddings. Then we'll feed those embeddings into a *recurrent neural network* (RNN), using an architecture called *AWD-LSTM*. The link to the paper https://arxiv.org/abs/1708.02182 <br>\n",
        "\n",
        "AWD-LSTM stands for **ASGD Weight Dropout LSTM**. The AWD-LSTM has been dominating the state-of-the-art language modeling. All the top research papers on word-level models incorporate AWD-LSTMs. \n",
        "\n",
        "As we discussed earlier, the embeddings in the pretrained model are merged with random embeddings added for words that weren't in the pretraining vocabulary. This is handled automatically inside `language_model_learner`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYocBy8HU3u8"
      },
      "source": [
        "learn = language_model_learner(\n",
        "    dls_lm, AWD_LSTM, drop_mult=0.3, \n",
        "    metrics=[accuracy]).to_fp32()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "zkJPHa3p9V-v",
        "outputId": "e1c601d8-adf1-4f0d-a65a-ebb513d1a278"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='1307' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.08% [1/1307 01:31<33:09:08]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Ez9pqrU3u8"
      },
      "source": [
        "`language_model_learner` automatically calls `freeze` when using a pretrained model (which is the default), so this will only train the embeddings (the only part of the model that contains randomly initialized weightsâ€”i.e., embeddings for words that are in our IMDb vocab, but aren't in the pretrained model vocab):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "LbpuSst-U3u8",
        "outputId": "d877bb56-4d7d-4814-fa7c-ab648f8ca4af"
      },
      "source": [
        "learn.fit_one_cycle(1, 0.014)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.034898</td>\n",
              "      <td>3.936011</td>\n",
              "      <td>0.298542</td>\n",
              "      <td>10:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwuDIc-2U3u8"
      },
      "source": [
        "### Saving and Loading Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlojDAp4U3u8"
      },
      "source": [
        "You can easily save the state of your model like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js4SwK7UU3u8",
        "outputId": "1cbbe1e2-7962-4bbe-cbbf-15ce82d1996b"
      },
      "source": [
        "learn.save('1epoch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/1epoch.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1MZqv1NU3u8"
      },
      "source": [
        "This will create a file in `learn.path/models/` named *1epoch.pth*. If you want to load your model in another machine after creating your `Learner` the same way, or resume training later, you can load the content of this file with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6p7j4WjU3u8"
      },
      "source": [
        "learn = learn.load('1epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx7XRGr7U3u8"
      },
      "source": [
        "Once the initial training has completed, we can continue fine-tuning the model after unfreezing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "UH2c0ZVnU3u8",
        "outputId": "739b6db0-c9fb-4efc-82f6-425201275e5b"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 3e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.738276</td>\n",
              "      <td>3.735943</td>\n",
              "      <td>0.321660</td>\n",
              "      <td>10:44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah91zkH3U3u8"
      },
      "source": [
        "Once this is done, we save all of our model except the final layer that converts activations to probabilities of picking each token in our vocabulary. The model not including the final layer is called the *encoder*. We can save it with `save_encoder`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZrhEBRYU3u8"
      },
      "source": [
        "learn.save_encoder('finetuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH-BbMS6Ic9S",
        "outputId": "08b1b832-a705-493d-d197-1ac818b7568a"
      },
      "source": [
        "learn.load_encoder('finetuned')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.text.learner.LMLearner at 0x7eff544b31d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWlUN34MU3u8"
      },
      "source": [
        "This completes the second stage of the text classification process: fine-tuning the language model. We can now use it to fine-tune a classifier using the IMDb sentiment labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpfewb0AU3u8"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NlwHybsU3u8"
      },
      "source": [
        "Before we move on to fine-tuning the classifier, let's quickly try something different: using our model to generate random reviews. Since it's trained to guess what the next word of the sentence is, we can use the model to write new reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "C-vdtWzxU3u8",
        "outputId": "83d7ddc3-8dfd-4c1f-b1d4-7c8beaa45431"
      },
      "source": [
        "TEXT = \"Stopping by Woods on a Snowy Evening\"\n",
        "N_WORDS = 50\n",
        "N_SENTENCES = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) #Lowering temperature will make the texts less randomized.\n",
        "         for _ in range(N_SENTENCES)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irxOqwQAU3u8",
        "outputId": "67ab1986-c93e-4cfe-c39f-5d5973b30841"
      },
      "source": [
        "print(\"\\n\".join(preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stopping by Woods on a Snowy Evening is pretty good . It is a very intriguing and well acted movie . When you see the hit and miss the DVD ( which i had heard about from a river in Kansas ) , you will understand it . Many great characters in\n",
            "Stopping by Woods on a Snowy Evening and thinking he would buy a house for the night . And there 's a more interesting scene in the ghetto where his girlfriend ( debra Paget ) decides to hang a date with him , as he is a couple of girls . But the movie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTqX9qhrU3u9"
      },
      "source": [
        "As you can see, we add some randomness (we pick a random word based on the probabilities returned by the model) so we don't get exactly the same review twice. Our model doesn't have any programmed knowledge of the structure of a sentence or grammar rules, yet it has clearly learned a lot about English sentences: we can see it capitalizes properly (*I* is just transformed to *i* because our rules require two characters or more to consider a word as capitalized, so it's normal to see it lowercased) and is using consistent tense. The general review makes sense at first glance, and it's only if you read carefully that you can notice something is a bit off. Not bad for a model trained in a couple of hours! \n",
        "\n",
        "But our end goal wasn't to train a model to generate reviews, but to classify them... so let's use this model to do just that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9fHGij0U3u9"
      },
      "source": [
        "### Creating the Classifier DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1msFKixU3u9"
      },
      "source": [
        "We're now moving from language model fine-tuning to classifier fine-tuning. To recap, a language model predicts the next word of a document, so it doesn't need any external labels. A classifier, however, predicts some external labelâ€”in the case of IMDb, it's the sentiment of a document.\n",
        "\n",
        "This means that the structure of our `DataBlock` for NLP classification will look very familiar. It's actually nearly the same as we've seen for the many image classification datasets we've worked with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LywpACaQU3u9",
        "outputId": "661af155-3841-4021-9047-68f67b9648bf"
      },
      "source": [
        "dls_clas = DataBlock(\n",
        "    blocks=(TextBlock.from_df('text', vocab=dls_lm.vocab),CategoryBlock),\n",
        "    get_x=ColReader('text'), \n",
        "    get_y=ColReader('label'), \n",
        "    splitter=RandomSplitter(0.1)\n",
        ").dataloaders(data, bs=128, seq_len=72)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "upg3xvx6U3u9",
        "outputId": "fe0274d8-24b2-486a-da1b-f91b1b2226ab"
      },
      "source": [
        "dls_clas.show_batch(max_n=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german suplex by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxmaj by now you 've probably heard a bit about the new xxmaj disney dub of xxmaj miyazaki 's classic film , xxmaj laputa : xxmaj castle xxmaj in xxmaj the xxmaj sky . xxmaj during late summer of 1998 , xxmaj disney released \" kiki 's xxmaj delivery xxmaj service \" on video which included a preview of the xxmaj laputa dub saying it was due out in \" 1 xxrep 3 9 \" . xxmaj it 's obviously way past that year now , but the dub has been finally completed . xxmaj and it 's not \" laputa : xxmaj castle xxmaj in xxmaj the xxmaj sky \" , just \" castle xxmaj in xxmaj the xxmaj sky \" for the dub , since xxmaj laputa is not such a nice word in xxmaj spanish ( even though they use the word xxmaj laputa many times</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxrep 3 * xxmaj warning - this review contains \" plot spoilers , \" though nothing could \" spoil \" this movie any more than it already is . xxmaj it really xxup is that bad . xxrep 3 * \\n\\n xxmaj before i begin , xxmaj i 'd like to let everyone know that this definitely is one of those so - incredibly - bad - that - you - fall - over - laughing movies . xxmaj if you 're in a lighthearted mood and need a very hearty laugh , this is the movie for you . xxmaj now without further ado , my review : \\n\\n xxmaj this movie was found in a bargain bin at wal - mart . xxmaj that should be the first clue as to how good of a movie it is . xxmaj secondly , it stars the lame action</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI8wb8JKU3u9"
      },
      "source": [
        "Looking at the `DataBlock` definition, every piece is familiar from previous data blocks we've built, with two important exceptions:\n",
        "\n",
        "- `TextBlock.from_df` no longer has the `is_lm=True` parameter.\n",
        "- We pass the `vocab` we created for the language model fine-tuning.\n",
        "\n",
        "The reason that we pass the `vocab` of the language model is to make sure we use the same correspondence of token to index. Otherwise the embeddings we learned in our fine-tuned language model won't make any sense to this model, and the fine-tuning step won't be of any use.\n",
        "\n",
        "By passing `is_lm=False` (or not passing `is_lm` at all, since it defaults to `False`) we tell `TextBlock` that we have regular labeled data, rather than using the next tokens as labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tk_ZBnfU3u9"
      },
      "source": [
        "learn_cls = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5, \n",
        "                                metrics=accuracy).to_fp32()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "2Rq3fz26MH5U",
        "outputId": "8b24636f-d0aa-4039-dd06-4baee0d3b6df"
      },
      "source": [
        "learn_cls.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=0.09120108485221863, lr_steep=0.009120108559727669)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODIzc6IU3u9"
      },
      "source": [
        "The final step prior to training the classifier is to load the encoder from our fine-tuned language model. We use `load_encoder` instead of `load` because we only have pretrained weights available for the encoder; `load` by default raises an exception if an incomplete model is loaded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaotBi6PU3u9"
      },
      "source": [
        "learn_cls = learn_cls.load_encoder('finetuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeisQMHKU3u9"
      },
      "source": [
        "### Fine-Tuning the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQ8L3dUU3u9"
      },
      "source": [
        "The last step is to train with discriminative learning rates and *gradual unfreezing*. For NLP classifiers, we find that unfreezing a few layers at a time makes a real difference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "Ei8ItPGmU3u9",
        "outputId": "e0745e16-3b9c-4f6c-c551-ea80745189e3"
      },
      "source": [
        "learn_cls.fit_one_cycle(1, 0.009)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.358101</td>\n",
              "      <td>0.205374</td>\n",
              "      <td>0.921800</td>\n",
              "      <td>01:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx95K__IU3u9"
      },
      "source": [
        "We can pass `-2` to `freeze_to` to freeze all except the last two parameter groups:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "Ha-8BCiNU3u9",
        "outputId": "b717b794-4dbb-4d66-f606-882a70640f26"
      },
      "source": [
        "learn_cls.freeze_to(-2)\n",
        "learn_cls.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.248828</td>\n",
              "      <td>0.185424</td>\n",
              "      <td>0.930400</td>\n",
              "      <td>01:26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGf_pI7rU3u9"
      },
      "source": [
        "Then we can unfreeze a bit more, and continue training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "MI6JMylEU3u9",
        "outputId": "c0222b45-de81-47ad-8b03-834bd3633cca"
      },
      "source": [
        "learn_cls.freeze_to(-3)\n",
        "learn_cls.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.191089</td>\n",
              "      <td>0.156836</td>\n",
              "      <td>0.941200</td>\n",
              "      <td>01:57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpOJmxP5U3u9"
      },
      "source": [
        "And finally, the whole model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "R_Vfua0sU3u9",
        "outputId": "50d9911b-4dfd-4079-a1e5-2d802ffaf201"
      },
      "source": [
        "learn_cls.unfreeze()\n",
        "learn_cls.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.162609</td>\n",
              "      <td>0.159636</td>\n",
              "      <td>0.942600</td>\n",
              "      <td>02:32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.149697</td>\n",
              "      <td>0.151581</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>02:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPEZe4eeU3u9"
      },
      "source": [
        "We reached 94.5% accuracy, which was state-of-the-art performance just three years ago. By training another model on all the texts read backwards and averaging the predictions of those two models, we can even get to 95.1% accuracy, which was the state of the art introduced by the ULMFiT paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P51JfoE5X_5g"
      },
      "source": [
        "### Saving the entire model as pkl file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUuFvtRkXz1i"
      },
      "source": [
        "learn_cls.export(fname=path/'imdb.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0zHcb1uYM4Q"
      },
      "source": [
        "loaded_model = load_learner(path/'imdb.pkl',cpu=False) # if model needs to be run on cpu make sure cpu=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9CWxa1nYSCu",
        "outputId": "51e542fe-dbfd-4046-abb4-6505940cf2cf"
      },
      "source": [
        "loaded_model.model     # loaded_model contains both encoder and pooling linear classifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): SentenceEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(52072, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(52072, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): LinBnDrop(\n",
              "        (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): Dropout(p=0.2, inplace=False)\n",
              "        (2): Linear(in_features=1200, out_features=50, bias=False)\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): LinBnDrop(\n",
              "        (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (1): Dropout(p=0.1, inplace=False)\n",
              "        (2): Linear(in_features=50, out_features=2, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKamcVyyS--y"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "P2oKow2LS6Jx",
        "outputId": "230fb777-7ad9-4fe9-e37c-ba82b5269d38"
      },
      "source": [
        "learn_cls.show_results()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>category_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos ( some spoilers included : ) \\n\\n xxmaj although , many commentators have called this film surreal , the term fits poorly here . xxmaj to quote from xxmaj encyclopedia xxmaj britannica 's , surreal means : \\n\\n \" fantastic or incongruous imagery \" : xxmaj one need n't explain to the unimaginative how many ways a plucky ten - year - old boy at large and seeking his fortune in the driver 's seat of a red xxmaj mustang could be fantastic : those curious might read xxmaj james xxmaj kincaid ; but if you asked said lad how he were incongruous behind the wheel of a sports car , he 'd surely protest , \" no way ! \" xxmaj what fantasies and incongruities the film offers mostly appear within the first fifteen minutes . xxmaj thereafter we get more iterations of the same , in an</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxmaj titanic directed by xxmaj james xxmaj cameron presents a fictional love story on the historical setting of the xxmaj titanic . xxmaj the plot is simple , xxunk , or not for those who love plots that twist and turn and keep you in suspense . xxmaj the end of the movie can be figured out within minutes of the start of the film , but the love story is an interesting one , however . xxmaj kate xxmaj winslett is wonderful as xxmaj rose , an aristocratic young lady betrothed by xxmaj cal ( billy xxmaj zane ) . xxmaj early on the voyage xxmaj rose meets xxmaj jack ( leonardo dicaprio ) , a lower class artist on his way to xxmaj america after winning his ticket aboard xxmaj titanic in a poker game . xxmaj if he wants something , he goes and gets it</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj here are the matches . . . ( adv . = advantage ) \\n\\n xxmaj the xxmaj warriors ( ultimate xxmaj warrior , xxmaj texas xxmaj tornado and xxmaj legion of xxmaj doom ) v xxmaj the xxmaj perfect xxmaj team ( mr xxmaj perfect , xxmaj ax , xxmaj smash and xxmaj crush of xxmaj demolition ) : xxmaj ax is the first to go in seconds when xxmaj warrior splashes him for the pin ( 4 - 3 adv . xxmaj warriors ) . i knew xxmaj ax was n't a healthy man but if he was that unhealthy why bother have him on the card ? xxmaj this would be his last xxup ppv . xxmaj eventually , both xxmaj legion of xxmaj doom and xxmaj demolition job out cheaply via double disqualification ( 2 - 1 adv . xxmaj warriors ) . xxmaj perfect</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxbos xxmaj wrestlemania 6 , is an entertaining xxmaj wrestlemania , if not an entirely successful one . xxmaj the xxmaj ultimate xxmaj challenge , is of course worth the price of admission alone , but once again as with a lot of the early xxmaj mania 's , there 's too much filler in between . xxmaj the crowd pops for almost everything , and as always , giving us the reliable announcing team of xxunk xxmaj body . xxmaj having a xxmaj face vs xxmaj face match as the main event for a xxmaj wrestlemania , was absolutely unheard of at this time , it only made things that much more tense . \\n\\n xxmaj matches . \\n\\n xxmaj koko xxup b. xxmaj ware / w xxmaj frankie xxmaj vs \" the xxmaj model \" xxmaj rick xxmaj martel . xxmaj for a 3 or so minute match</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xxbos xxmaj the freedom of having your own xxmaj sea xxmaj going xxmaj power xxmaj boat , the excitement of going on underwater adventures a rugged , an 's man of an adventurer and xxunk so well endowed ! ) assistants in fine xxmaj bikinis were all definite selling points for \" sea xxup xxunk - 61 ) . \\n\\n xxmaj just what was the reason for producing a sort of sea going \" gun for hire \" * series . xxmaj let 's look closely now . xxmaj there must be a some clues around . \\n\\n xxmaj if we were to look back just a little , we see the xxup rko xxmaj radio xxmaj pictures production of xxup underwater ! ( 1955 ) . xxmaj it starred xxmaj jane xxmaj russell , xxmaj gilbert xxmaj roland , xxmaj richard xxmaj egan and xxmaj lori xxmaj nelson as</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xxbos xxmaj that word ' true ' in this film 's title got my alarm bells ringing . xxmaj they rang louder when a title card referred to xxmaj america 's xxmaj civil xxmaj war as the ' war xxmaj between the xxmaj states ' ( the xxunk preferred by die - hard southerners ) . xxmaj jesse xxmaj james -- thief , slave - holder and murderer -- is described as a quiet , gentle farm boy . \\n\\n xxmaj how dishonest is this movie ? xxmaj there is xxup no mention of slavery , far less of the documented fact that xxmaj jesse xxmaj james 's poor xxunk mother owned slaves before the war , and that xxmaj jesse and his brother xxmaj frank actively fought to preserve slavery . xxmaj according to this movie , all those xxmaj civil xxmaj war soldiers were really fighting to decide</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xxbos xxmaj years ago , when xxup darling xxup lili played on xxup tv , it was always the pan and scan version , which i hated and decided to wait and see the film in its proper widescreen format . xxmaj so when i saw an inexpensive xxup dvd of this xxmaj julie xxmaj andrews / xxmaj blake xxmaj edwards opus , i decided to purchase and watch it once and for all . \\n\\n xxmaj boy , what a terrible film . xxmaj it 's so bad and on so many levels that i really do not know where to start in describing where and when it goes so horribly wrong . xxmaj looking at it now , it 's obvious to any fans of movies that xxmaj blake xxmaj edwards created this star vehicle for his wife simply because so many other directors had struck gold with</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xxbos xxup spoilers xxup herein \\n\\n xxmaj my xxmaj high xxmaj school did all they could to try and motivate us for exams . xxmaj but the most memorable method they used to get us into the right state of mind was a guest speaker , who was none other than xxmaj australian xxmaj kickboxing 's favorite son , xxmaj stan \" the xxmaj man \" xxmaj xxunk . xxmaj the first mistake they made was giving this guy a microphone , because he was screaming half the time despite us sitting no more than 3 or 4 feet away from him . xxmaj now , his speech was full of the usual \" if you fail to prepare , then prepare to fail \" stuff , but there were various instances where i got really worked up . xxmaj the guy stood there in front of us preaching how</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>xxbos * xxmaj some spoilers * \\n\\n xxmaj this movie is sometimes subtitled \" life xxmaj everlasting . \" xxmaj that 's often taken as reference to the final scene , but more accurately describes how dead and buried this once - estimable series is after this sloppy and illogical send - off . \\n\\n xxmaj there 's a \" hey kids , let 's put on a show air \" about this telemovie , which can be endearing in spots . xxmaj some fans will feel like insiders as they enjoy picking out all the various cameo appearances . xxmaj co - writer , co - producer xxmaj tom xxmaj fontana and his pals pack the goings - on with friends and favorites from other shows , as well as real xxmaj baltimore personages . \\n\\n xxmaj that 's on top of the returns of virtually all the members</td>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tPo6mjByTXwR",
        "outputId": "5db90e9f-de92-46e5-ef71-ed3a616a04e9"
      },
      "source": [
        "loaded_model.predict('I like the movie a lot. However I am disappointed with little role for Scarlett Johansson.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('positive', tensor(1), tensor([0.1367, 0.8633]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z8JHNUUToXr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}